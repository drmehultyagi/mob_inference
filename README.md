## âœ¨ Core Features

*   **ğŸ“± Run Locally, Fully Offline:** Experience the magic of GenAI without an internet connection. All processing happens directly on your device.
*   **ğŸ¤– Choose Your Model:** Easily switch between different models from Hugging Face and compare their performance.
*   **ğŸ–¼ï¸ Ask Image:** Upload an image and ask questions about it. Get descriptions, solve problems, or identify objects.
*   **âœï¸ Prompt Lab:** Summarize, rewrite, generate code, or use freeform prompts to explore single-turn LLM use cases.
*   **ğŸ’¬ AI Chat:** Engage in multi-turn conversations.
*   **ğŸ“Š Performance Insights:** Real-time benchmarks (TTFT, decode speed, latency).
*   **ğŸ§© Bring Your Own Model:** Test your local LiteRT `.task` models.
*   **ğŸ”— Developer Resources:** Quick links to model cards and source code.

## ğŸ Get Started in Minutes!

1.  **Download the App:** Grab the [**latest APK**](https://github.com/google-ai-edge/gallery/releases/latest/download/ai-edge-gallery.apk).
2.  **Install & Explore:** For detailed installation instructions (including for corporate devices) and a full user guide, head over to our [**Project Wiki**](https://github.com/google-ai-edge/gallery/wiki)!

## ğŸ› ï¸ Technology Highlights

*   **Google AI Edge:** Core APIs and tools for on-device ML.
*   **LiteRT:** Lightweight runtime for optimized model execution.
*   **LLM Inference API:** Powering on-device Large Language Models.
*   **Hugging Face Integration:** For model discovery and download.

## ğŸ”— Useful Links

*   [**Project Wiki (Detailed Guides)**](https://github.com/google-ai-edge/gallery/wiki)
*   [Hugging Face LiteRT Community](https://huggingface.co/litert-community)
*   [LLM Inference guide for Android](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference/android)
*   [Google AI Edge Documentation](https://ai.google.dev/edge)
